# 実装設計書：GraphRAGを用いたアンカー機能が少ない掲示板の文脈理解とリアルタイムQ&Aシステム（分離システム版）

## 第1部：システムアーキテクチャ

本設計は、既存の掲示板システムを**読み取り専用のデータソース**として扱い、完全に独立したRAG（Retrieval-Augmented Generation）システムを構築することを目的とします。既存システムへの書き込みや変更は一切行いません。

### 1.1. システム構成要素

システムは、明確に分離された2つの領域で構成されます。

1.  **既存システム（読み取り専用）**:
    *   **掲示板クローラー**: 継続的に掲示板からレスを収集する外部プログラム（変更対象外）。
    *   **掲示板データベース (PostgreSQL)**: クローラーによって収集されたレスの生データを格納するデータベース（変更対象外）。

2.  **新規RAGシステム**:
    *   **データ同期・グラフ構築パイプライン**: 既存の掲示板DBからデータを定期的に読み込み、RAGシステム用のナレッジグラフとベクトルデータを構築・更新するバッチプロセス。
    *   **RAG用PostgreSQLデータベース**: 同期パイプラインによって生成された**ナレッジグラフ（ノードと関係性）**を格納するための専用データベース。
    *   **ChromaDBベクターストア**: レスの埋め込みベクトルを格納し、高速な類似度検索を提供する専用のベクトルデータベース。
    *   **FastAPIバックエンド（リアルタイムAPI）**: ユーザーからの質問を受け付け、RAG用のDBとChromaDBを利用して回答を生成するAPIサーバー。
    *   **Reactフロントエンド（インタラクティブUI）**: ユーザーが質問を入力し、リアルタイムで回答を受け取るためのWebインターフェース。

### 1.2. データフロー

データは一方向に流れます。

1.  **オフライン（バッチ処理）**:
    *   データ同期パイプラインが、既存の掲示板DBに接続し、新しいレスを読み取ります。
    *   読み取ったレスの本文から、LLMを用いて意味的な関係性（返信など）を推論します。
    *   各レスに対して、後続20件のレスへの構造的な関係性を付与します。
    *   生成されたグラフデータ（ノード、関係性）をRAG用PostgreSQLに保存します。
    *   レス本文の埋め込みベクトルを生成し、ChromaDBに保存します。

2.  **オンライン（リアルタイム処理）**:
    *   ユーザーがReactフロントエンドから質問を送信します。
    *   FastAPIバックエンドがリクエストを受け取ります。
    *   バックエンドは、**ChromaDB**にベクトル検索を、**RAG用PostgreSQL**にグラフ探索をクエリします。**（既存の掲示板DBにはアクセスしません）**
    *   取得した文脈情報を基にLLMが回答を生成し、フロントエンドにストリーミングで返します。

このアーキテクチャにより、リアルタイムのQ&A処理が既存のデータベースに負荷をかけることなく、RAGシステム内で完結し、高いパフォーマンスと独立性を確保します。

---

## 第2部：データ層の設計

### 2.1. 外部データソース（読み取り専用）

RAGシステムのデータソースとして、以下のスキーマを持つ既存の掲示板データベースの`res`テーブルを読み取り専用で利用します。

**表1：既存の掲示板データベーススキーマ（ソース）**

| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `no` | `integer` | レス番号（主キー） |
| `name_and_trip` | `text` | 名前とトリップ |
| `datetime` | `timestamp without time zone` | 投稿日時 |
| `datetime_text` | `text` | 投稿日時のテキスト表現 |
| `id` | `text` | ユーザーID |
| `main_text` | `text` | レス本文 |
| `main_text_html` | `text` | レス本文（HTML） |
| `oekaki_id` | `integer` | お絵かきID |

### 2.2. RAGシステム内部のデータストア

RAGシステムは、リアルタイム検索とグラフ探索のために、独自の最適化されたデータストアを保持します。

#### 2.2.1. RAG用PostgreSQL（グラフストア）

LLMやルールによって生成されたグラフ構造を格納します。この独自のデータベースを持つことで、元のデータ構造を変更することなく、複雑な関係性を自由にモデル化できます。

**表2：RAG用PostgreSQLデータベーススキーマ**

| テーブル名 | カラム名 | データ型 | 説明 |
| :--- | :--- | :--- | :--- |
| **posts** | `post_id` | `UUID` | 投稿の一意なID（PK） |
| | `source_post_no` | `INTEGER` | 既存DBの`res.no`に対応するレス番号 |
| | `content` | `TEXT` | 投稿の本文 |
| | `timestamp` | `TIMESTAMPTZ` | 投稿日時 |
| **relationships** | `relationship_id` | `UUID` | リレーションシップの一意なID（PK） |
| | `source_node_id` | `UUID` | 関係の始点となる投稿のID |
| | `target_node_id` | `UUID` | 関係の終点となる投稿のID |
| | `relationship_type` | `TEXT` | 関係のタイプ（'IS_REPLY_TO', 'IS_SEQUENTIAL_TO'など） |
| | `properties` | `JSONB` | 関係の追加プロパティ（信頼度スコアなど） |

#### 2.2.2. ChromaDB（ベクトルストア）

投稿本文のセマンティックな意味を捉えた埋め込みベクトルを格納します。独立したサービスとして実行され、高速な類似度検索を担当します。

---

## 第3部：データ同期・グラフ構築パイプライン

このパイプラインは、既存のDBからRAGシステムへデータを変換・転送するETL（Extract, Transform, Load）プロセスです。

### 3.1. パイプラインの処理フロー

定期的に（例：cronジョブで10分ごとに）実行されるPythonスクリプトとして実装します。

1.  **差分抽出 (Extract)**:
    *   RAG用PostgreSQLに記録されている、最後に処理したレスの`no`（`source_post_no`）を取得します。
    *   既存の掲示板DBに接続し、その`no`よりも大きいすべての新しいレスを取得します。

2.  **変換とグラフ構築 (Transform)**:
    *   取得した各レスに対して、以下の処理を行います。
        *   **ノード生成**: RAG用DBの`posts`テーブルに新しいレコードを作成します。
        *   **ベクトル生成**: `main_text`から埋め込みベクトルを生成します。
        *   **意味的エッジ推論**: `main_text`をLLMに渡し、先行するレスへの`IS_REPLY_TO`関係を推論させます。
        *   **構造的エッジ生成**: 既存の掲示板DBに対して`SELECT * FROM res WHERE no > {current_no} ORDER BY no ASC LIMIT 20`のようなクエリを実行し、後続20件のレスを取得します。取得したレスそれぞれに対して、`IS_SEQUENTIAL_TO`という関係性のエッジを生成します。

3.  **書き込み (Load)**:
    *   **グラフデータ**: 生成されたノード（投稿）とエッジ（関係性）の情報を、RAG用PostgreSQLに一括で書き込みます。
    *   **ベクトルデータ**: 生成された埋め込みベクトルと、対応する`post_id`をメタデータとしてChromaDBに書き込みます。

---

## 第4部：リアルタイムQ&Aバックエンドサービス (FastAPI)

ユーザーからのリクエストを処理するAPIサーバーです。

### 4.1. GraphRAG検索ワークフロー（LangGraph）

ユーザーの質問に対する回答生成プロセスは、LangGraphを用いて状態機械としてモデル化します。

1.  **`vector_retriever`**: ユーザーの質問をベクトル化し、**ChromaDB**にクエリを投げて、意味的に関連性の高い投稿（グラフ探索の開始点）を複数取得します。
2.  **`graph_traverser`**: `vector_retriever`で見つかった投稿を開始点として、**RAG用PostgreSQL**にクエリを投げます。再帰的なSQLクエリを用いて、`IS_REPLY_TO`（意味的な返信）と`IS_SEQUENTIAL_TO`（構造的な後続レス）の両方の関係性を辿り、広範な会話コンテキストを収集します。
3.  **`context_synthesizer`**: 収集したコンテキスト情報を統合し、LLMが理解しやすい形式に整形します。
4.  **`response_generator`**: 整形されたコンテキストと元の質問を基に、LLMが最終的な回答を生成します。

このプロセス全体を通じて、**既存の掲示板データベースへのアクセスは一切発生しない**ため、リアルタイム性とスケーラビリティが保証されます。

---

## 第5部：デプロイメントと運用

DockerとDocker Composeを用いて、RAGシステム全体をコンテナ化してデプロイします。

### 5.1. Docker Compose構成

`docker-compose.yml`は、新規RAGシステムのコンポーネントのみを定義します。

1.  **`rag-postgres`**: RAG用のPostgreSQLサービス。
2.  **`chroma`**: ChromaDBサービス。
3.  **`api`**: FastAPIバックエンドサービス。このサービスには、**2つのデータベース接続情報**（`RAG_DATABASE_URL`と`SOURCE_DATABASE_URL`）を環境変数として渡します。`SOURCE_DATABASE_URL`はデータ同期パイプラインが使用し、`RAG_DATABASE_URL`はリアルタイムAPIが使用します。
4.  **`frontend`**: Reactアプリケーションを配信するNginxサービス。
5.  **`sync-worker`**: データ同期パイプラインを定期実行するためのサービス。`api`サービスと同じDockerイメージを使い、同期スクリプトを実行するコマンドを指定します。

この構成により、既存システムとは完全に分離された、独立したRAG環境を簡単に構築・運用できます。

---

## 第6部：結論

本設計書は、既存の掲示板データベースを一切変更することなく、そのデータを活用して高度な質問応答機能を実現するための、分離型GraphRAGシステムの実装計画を提示しました。データ同期パイプラインによって既存データからナレッジグラフを構築し、リアルタイムAPIはそのグラフのみを参照することで、システムの独立性、パフォーマンス、および安全性を確保します。